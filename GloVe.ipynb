{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e606e863",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-terrier in c:\\users\\jbies\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: nptyping in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: sklearn in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (2.11.3)\n",
      "Requirement already satisfied: pyjnius~=1.3.0 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (1.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (1.0.1)\n",
      "Requirement already satisfied: deprecation in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (2.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (1.4.1)\n",
      "Requirement already satisfied: dill in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (0.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (1.6.2)\n",
      "Requirement already satisfied: matchpy in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: wget in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (0.12.2)\n",
      "Requirement already satisfied: ir-measures>=0.2.0 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (2.25.1)\n",
      "Requirement already satisfied: chest in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (8.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (1.20.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (4.59.0)\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from python-terrier) (0.5.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (4.6.3)\n",
      "Requirement already satisfied: ijson>=3.1.3 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (3.1.4)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (4.9.3)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (5.4.1)\n",
      "Requirement already satisfied: lz4>=3.1.1 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (4.0.0)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.2.1)\n",
      "Requirement already satisfied: pytrec-eval-terrier==0.5.1 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-measures>=0.2.0->python-terrier) (0.5.1)\n",
      "Requirement already satisfied: pyndeval>=0.0.2 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-measures>=0.2.0->python-terrier) (0.0.2)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from ir-measures>=0.2.0->python-terrier) (1.0.10)\n",
      "Requirement already satisfied: cython in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from pyjnius~=1.3.0->python-terrier) (0.29.23)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from pyjnius~=1.3.0->python-terrier) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from requests->python-terrier) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from requests->python-terrier) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from requests->python-terrier) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from requests->python-terrier) (4.0.0)\n",
      "Requirement already satisfied: cbor>=1.0.0 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n",
      "Requirement already satisfied: heapdict in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from deprecation->python-terrier) (20.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from jinja2->python-terrier) (1.1.1)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: typish>=1.7.0 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from nptyping->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from packaging->deprecation->python-terrier) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from pandas->python-terrier) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from pandas->python-terrier) (2.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from sklearn->python-terrier) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->python-terrier) (2.1.0)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\jbies\\anaconda3\\lib\\site-packages (from statsmodels->python-terrier) (0.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.8.0 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install python-terrier\n",
    "import pyterrier as pt\n",
    "import numpy as np\n",
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3364c969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:35:55.349 [main] WARN org.terrier.applications.batchquerying.TRECQuery - trec.encoding is not set; resorting to platform default (windows-1252). Retrieval may be platform dependent. Recommend trec.encoding=UTF-8\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pt.get_dataset(\"trec-deep-learning-passages\")\n",
    "train_topics = dataset.get_topics(\"train\")\n",
    "train_qrels = dataset.get_qrels(\"train\")\n",
    "train_topics = train_topics.sort_values(by='qid', ascending=True)[3:]\n",
    "train_qrels = train_qrels.sort_values(by='qid', ascending=True)[3:]\n",
    "\n",
    "# A simple join operation on the qids, as we have much more queries than qrels, we want to only use those\n",
    "# queries with a qrel for optimal training performances. \n",
    "temp = pd.merge(train_topics, train_qrels, left_on='qid', right_on='qid')\n",
    "# Make the new train_topics dataframe with only those queries that have a qrel\n",
    "train_topics_100 = pd.concat([temp['qid'], temp['query']], axis=1, keys=['qid', 'query'])\n",
    "# print(train_topics_100.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aff2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and only get the first 100 queries (with qrels), save those as a csv\n",
    "# train_topics_100.drop_duplicates(inplace=True)\n",
    "# train_topics_100 = train_topics_100[:100]\n",
    "# train_topics_100.to_csv(\"train_topics_100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65302afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_topics_100 = pd.read_csv(\"train_topics_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84ec8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the qrels for the 100 queries that we have selected, and save as a csv\n",
    "# train_qrel_100 = pd.concat([temp['qid'], temp['docno'], temp['label']], axis=1, keys=['qid', 'docno', 'label'])\n",
    "# train_qrel_100.head(100)\n",
    "# train_qrel_100.to_csv(\"train_qrel_100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cbf4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qrel_100 = pd.read_csv(\"train_qrel_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f73970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire corpus of the MS Marco dataset\n",
    "corpus = './corpus/collection.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47ac9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all documents in a dataframe and lowercase the passages\n",
    "# all_documents = pd.read_csv(corpus, sep='\\t', names=(\"doc_id\",\"passage\"))\n",
    "# all_documents['passage'] = documents['passage'].apply(lambda x: x.lower())\n",
    "# all_documents.to_csv(\"all_documents_corpus.csv\", index=\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d360c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = pd.read_csv(\"all_documents_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da44fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = \"./glove.6B.50d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "338671f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model():\n",
    "    glove_model = {}\n",
    "    with open(glove_file,'r',encoding='utf8') as f:\n",
    "        print(\"Execution here\")\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f20e3c83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution here\n",
      "400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "model = load_glove_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7013424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note to self - check length of the vector if it is 50 for Glove\n",
    "\n",
    "# Function returning vector reperesentation of a document\n",
    "def get_embedding(doc_tokens):\n",
    "    embeddings = []\n",
    "    if len(doc_tokens)<1:\n",
    "        return np.zeros(50)\n",
    "    else:\n",
    "        for word in doc_tokens:\n",
    "            #if token exists in the trained model's vocabulary then fetch its vector\n",
    "            try:\n",
    "                embeddings.append(model[word])\n",
    "            #if it is an out-of-vocabulary word, generate a random vector of len 300\n",
    "            except:\n",
    "                embeddings.append(np.random.rand(50))\n",
    "            \n",
    "\n",
    "    # Note to self - understand why we are computing mean of these vectors        \n",
    "    # mean the vectors of individual words to get the vector of the document\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6425ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2e37b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents['vector'] = documents['passage'].apply(lambda x :get_embedding(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10d3cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents.to_csv(\"passage_vectors_glove50d.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5368e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_topics_100['vector'] = train_topics_100['query'].apply(lambda x :get_embedding(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ebf2f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_topics_100.to_csv(\"queries_vectors_glove50d.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb151d45",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = pd.read_csv(\"passage_vectors_glove50d.csv\")\n",
    "train_topics_100 = pd.read_csv(\"queries_vectors_glove50d.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbaa9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "docs_1000 = documents.iloc[:1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents.iloc[23]['vector'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a04fd516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [02:42, ?it/s]\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U813'), dtype('<U813')) -> dtype('<U813')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUFuncTypeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-f66056618fc7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m         \u001B[0mpid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpassage\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'doc_id'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mp_vec\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpassage\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'vector'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m         \u001B[0msim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mspatial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdistance\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcosine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mq_vec\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp_vec\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mfinal_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfinal_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'qID'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mqid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'passageID'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mpid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'cSim'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0msim\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001B[0m in \u001B[0;36mcosine\u001B[1;34m(u, v, w)\u001B[0m\n\u001B[0;32m    773\u001B[0m     \u001B[1;31m# cosine distance is also referred to as 'uncentered correlation',\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    774\u001B[0m     \u001B[1;31m#   or 'reflective correlation'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 775\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mcorrelation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcentered\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    776\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001B[0m in \u001B[0;36mcorrelation\u001B[1;34m(u, v, w, centered)\u001B[0m\n\u001B[0;32m    723\u001B[0m         \u001B[0mu\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mu\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mumu\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    724\u001B[0m         \u001B[0mv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mv\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mvmu\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 725\u001B[1;33m     \u001B[0muv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maverage\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mu\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    726\u001B[0m     \u001B[0muu\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maverage\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msquare\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    727\u001B[0m     \u001B[0mvv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maverage\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msquare\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUFuncTypeError\u001B[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U813'), dtype('<U813')) -> dtype('<U813')"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame(columns=['qID', 'passageID', 'cSim'])\n",
    "start = time.time()    \n",
    "for idx1, query in train_topics_100.iterrows():\n",
    "    qid = query['qid']\n",
    "    q_vec = query['vector']\n",
    "    for idx2, passage in docs_1000.iterrows():\n",
    "        pid = passage['doc_id']\n",
    "        p_vec = passage['vector']\n",
    "        sim = 1 - spatial.distance.cosine(q_vec, p_vec)\n",
    "            \n",
    "        final_df = final_df.append({'qID': qid, 'passageID': pid, 'cSim': sim}, ignore_index=True)\n",
    "            \n",
    "final_df.to_csv('test.csv', index=False)\n",
    "end = time.time()\n",
    "print('took: ', end-start, ' time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668e500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}